{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "from pytorch3d.io import load_obj\n",
    "from pytorch3d.ops import sample_farthest_points\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZEKOREA_INFERENCE =  '/workspace/SilhouettesbasedHSE/output/sizekorea'\n",
    "SIZEKOREA_RVH = '/workspace/datasets/sizekorea/rvh_test'\n",
    "\n",
    "OUTPUT_PATH = '/workspace/SilhouettesbasedHSE/merge_rvh_inference'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELING_CSV_PATH = '/workspace/RVH_Mesh_Registration/RVH_result_labeling.csv'\n",
    "\n",
    "def get_label_names(csv_path):\n",
    "    labeled_names = set()\n",
    "\n",
    "    with open(csv_path, 'rt') as f:\n",
    "        for l in f.readlines():\n",
    "            l = l.strip()\n",
    "            rvh_name, label, _ = l.split(',')\n",
    "\n",
    "            if label == '1':\n",
    "                labeled_names.add(rvh_name)\n",
    "\n",
    "    return labeled_names\n",
    "\n",
    "names = list(get_label_names(LABELING_CSV_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "random.shuffle(names)\n",
    "\n",
    "for n in names[:300]: \n",
    "    rvh = f'/workspace/datasets/sizekorea/rvh_test/{n}/{n}E_m.obj'\n",
    "    merge = f'/workspace/SilhouettesbasedHSE/output/sizekorea/{n}/merged.obj'\n",
    "    v_rvh, _, _ = load_obj(rvh)\n",
    "    \n",
    "    v_rvh, _ = sample_farthest_points(v_rvh.unsqueeze(0), K=6890)\n",
    "    v_rvh = v_rvh[0]\n",
    "\n",
    "    with open(merge, 'rt') as f:\n",
    "        lines = f.readlines()\n",
    "        y_arr = np.array([l.split()[2] for l in lines], dtype=np.float32)\n",
    "        \n",
    "    min_y = y_arr.min()\n",
    "    v_rvh[:, 1] += min_y - v_rvh[:, 1].min()\n",
    "\n",
    "    with open(os.path.join(OUTPUT_PATH, f'{n}.obj'),'wt') as f:\n",
    "        f.writelines(lines)\n",
    "\n",
    "        for v in v_rvh:\n",
    "            x, y, z = v\n",
    "            f.write(f'v {x} {y} {z} 0.000000 0.000000 1.000000\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_list = []\n",
    "\n",
    "for n in names[:300]:\n",
    "    scan = f'/workspace/datasets/sizekorea/rvh_test/{n}/{n}E_m.obj'\n",
    "\n",
    "    v_scan, _, _ = load_obj(scan)\n",
    "    v_scan,_   = sample_farthest_points(v_scan[None], K=6890)\n",
    "    scan_list.append(v_scan)\n",
    "\n",
    "\n",
    "scan_arr = torch.cat(scan_list)\n",
    "\n",
    "rvh_list = []\n",
    "hse_list = []\n",
    "\n",
    "for n in names[:300]:\n",
    "    rvh = f'/workspace/SilhouettesbasedHSE/output/sizekorea/{n}/gt.obj'\n",
    "    hse = f'/workspace/SilhouettesbasedHSE/output/sizekorea/{n}/mesh_out.obj'\n",
    "\n",
    "    v_rvh, _, _ = load_obj(rvh)\n",
    "    v_hse, _, _ = load_obj(hse)\n",
    "\n",
    "    rvh_list.append(v_rvh)\n",
    "    hse_list.append(v_hse)\n",
    "\n",
    "rvh_arr = torch.cat(rvh_list)\n",
    "hse_arr = torch.cat(hse_list)\n",
    "\n",
    "rvh_arr = rvh_arr.reshape(scan_arr.shape)\n",
    "hse_arr = hse_arr.reshape(scan_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.dummy import Pool \n",
    "\n",
    "DIR_PATH = '/workspace/SilhouettesbasedHSE/concat_sizekorea'\n",
    "\n",
    "def _write_obj(name, scan, rvh, hse):\n",
    "    lines = []\n",
    "    \n",
    "    rgbs = [\n",
    "        [1.0, 0.0, 0.0],\n",
    "        [0.0, 1.0, 0.0],\n",
    "        [0.0, 0.0, 1.0]\n",
    "    ]\n",
    "\n",
    "    for s, rgb in zip([scan, rvh, hse], rgbs):\n",
    "        r,g,b = rgb\n",
    "        for x,y,z in s:\n",
    "            l = f'v {x} {y} {z} {r} {g} {b}\\n'\n",
    "            lines.append(l)\n",
    "\n",
    "    with open(name, 'wt') as f:\n",
    "        f.writelines(lines)\n",
    "\n",
    "def worker(args):\n",
    "    name, v_scan, v_rvh, v_hse = args\n",
    "\n",
    "    min_y = min(v_scan[:, 1].min(), v_rvh[:, 1].min(),  v_hse[:, 1].min())\n",
    "    \n",
    "    v_scan[:, 1] += min_y - v_scan[:, 1].min() \n",
    "    v_rvh[:, 1] += min_y - v_rvh[:, 1].min() \n",
    "    v_hse[:, 1] += min_y - v_hse[:, 1].min()\n",
    "\n",
    "    v_scan = v_scan.clone()\n",
    "    v_rvh = v_rvh.clone()\n",
    "    v_hse = v_hse.clone()\n",
    "\n",
    "    v_scan[:, 0] -= v_scan[:,0].max() - v_scan[:, 0].min() + 0.1\n",
    "    v_hse[:, 0] += v_hse[:,0].max() - v_hse[:, 0].min() + 0.1\n",
    "\n",
    "    scan_height = v_scan[:,1].max() - v_scan[:, 1].min()\n",
    "    rvh_height = v_rvh[:,1].max() - v_rvh[:, 1].min()\n",
    "    hse_height = v_hse[:,1].max() - v_hse[:, 1].min()\n",
    "\n",
    "    v_rvh[:, 1] *= scan_height / rvh_height\n",
    "    v_hse[:, 1] *= scan_height / hse_height\n",
    "\n",
    "    path = os.path.join(DIR_PATH, f'{name}.obj')\n",
    "    _write_obj(path, v_scan, v_rvh, v_hse)\n",
    "\n",
    "args = zip(names[:300], scan_arr, rvh_arr, hse_arr)\n",
    "\n",
    "with Pool() as pool:\n",
    "    pool.map(worker, args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
